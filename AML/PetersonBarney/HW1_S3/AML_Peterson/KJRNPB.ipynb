{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Nearest point classifier\n",
    "In this program, we classify the phonemes according to how close they are to the center of gravity of the phonemes in the training set."
   ],
   "id": "129120529823b9b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We use pandas to read the data from Peterson Barney",
   "id": "9ea28d5203708281"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-14T12:04:52.810112Z",
     "start_time": "2024-09-14T12:04:52.805727Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:03:26.095129Z",
     "start_time": "2024-09-14T10:03:26.072098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vowel_data = pd.read_csv('verified_pb.data',delim_whitespace=True, header = None)\n",
    "print(vowel_data)"
   ],
   "id": "a7b4dc5e8516b42e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3      4      5       6       7\n",
      "0     1   1   1  IY  160.0  240.0  2280.0  2850.0\n",
      "1     1   1   1  IY  186.0  280.0  2400.0  2790.0\n",
      "2     1   1   2  IH  203.0  390.0  2030.0  2640.0\n",
      "3     1   1   2  IH  192.0  310.0  1980.0  2550.0\n",
      "4     1   1   3  EH  161.0  490.0  1870.0  2420.0\n",
      "...  ..  ..  ..  ..    ...    ...     ...     ...\n",
      "1515  3  76   8  UH  322.0  610.0  1550.0  3400.0\n",
      "1516  3  76   9  UW  345.0  520.0  1250.0  3460.0\n",
      "1517  3  76   9  UW  334.0  500.0  1140.0  3380.0\n",
      "1518  3  76  10  ER  308.0  740.0  1850.0  2160.0\n",
      "1519  3  76  10  ER  328.0  660.0  1830.0  2200.0\n",
      "\n",
      "[1520 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferch\\AppData\\Local\\Temp\\ipykernel_26748\\1362900325.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  vowel_data = pd.read_csv('verified_pb.data',delim_whitespace=True, header = None)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the pandas file, there are three different types of people: Man (1), Woman (2), Child (3). Each person pronounces twice the different phonemes enumerated from 1 to 10 which yields the results in columns 4,5,6,7. We choose 80% of each group as training data. With this, we will average the vectors and will predict which are the vowels pronounced in the test set depending on which is the closest phoneme to them.  ",
   "id": "7e2c139d68c0f272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We divide the data into the three types of people. Notice that each person has 20 recordings, so we divide the amount of lines by 20 to get the amount of people in each group.",
   "id": "edd0503e53901b99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T11:10:08.605532Z",
     "start_time": "2024-09-14T11:10:08.599826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "type1_vowel = vowel_data[vowel_data.iloc[:,0] == 1]\n",
    "type2_vowel = vowel_data[vowel_data.iloc[:,0] == 2]\n",
    "type3_vowel = vowel_data[vowel_data.iloc[:,0] == 3]\n",
    "type1_length = int ((type1_vowel.shape[0])/20)\n",
    "type2_length = int ((type2_vowel.shape[0])/20)\n",
    "type3_length = int ((type3_vowel.shape[0])/20)"
   ],
   "id": "47abad233c20341e",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T11:10:09.911878Z",
     "start_time": "2024-09-14T11:10:09.908296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type1_length)\n",
    "print(type2_length)\n",
    "print(type3_length)"
   ],
   "id": "187ba0bb4c6ad695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "28\n",
      "15\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# We choose the training data:\n",
    "\n",
    "We use 80% of each of the groups as training data"
   ],
   "id": "2a3567dbba290d89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T11:15:15.766042Z",
     "start_time": "2024-09-14T11:15:15.762572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "type1_training_length = int(type1_length*0.8)\n",
    "type2_training_length = int(type2_length*0.8)\n",
    "type3_training_length = int(type3_length*0.8)\n",
    "type1_training = type1_vowel.iloc[0:type1_training_length*20,:]\n",
    "type2_training = type2_vowel.iloc[0:type2_training_length*20,:]\n",
    "type3_training = type3_vowel.iloc[0:type3_training_length*20,:]"
   ],
   "id": "872960cfafdabe6b",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T11:15:17.833626Z",
     "start_time": "2024-09-14T11:15:17.823357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type1_training)\n",
    "print(type2_training)\n",
    "print(type3_training)"
   ],
   "id": "19d2dfd16273172c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2   3      4      5       6       7\n",
      "0    1   1   1  IY  160.0  240.0  2280.0  2850.0\n",
      "1    1   1   1  IY  186.0  280.0  2400.0  2790.0\n",
      "2    1   1   2  IH  203.0  390.0  2030.0  2640.0\n",
      "3    1   1   2  IH  192.0  310.0  1980.0  2550.0\n",
      "4    1   1   3  EH  161.0  490.0  1870.0  2420.0\n",
      "..  ..  ..  ..  ..    ...    ...     ...     ...\n",
      "515  1  26   8  UH  125.0  462.0   976.0  2450.0\n",
      "516  1  26   9  UW  120.0  324.0   708.0  2440.0\n",
      "517  1  26   9  UW  157.0  387.0   786.0  2518.0\n",
      "518  1  26  10  ER  122.0  488.0  1468.0  1712.0\n",
      "519  1  26  10  ER  118.0  472.0  1465.0  1725.0\n",
      "\n",
      "[520 rows x 8 columns]\n",
      "      0   1   2    3      4      5       6       7\n",
      "660   2  34   1  *IY  230.0  370.0  2670.0  3100.0\n",
      "661   2  34   1   IY  234.0  390.0  2760.0  3060.0\n",
      "662   2  34   2   IH  234.0  468.0  2330.0  2930.0\n",
      "663   2  34   2   IH  205.0  410.0  2380.0  2950.0\n",
      "664   2  34   3   EH  190.0  550.0  2200.0  2880.0\n",
      "...  ..  ..  ..  ...    ...    ...     ...     ...\n",
      "1095  2  55   8   UH  235.0  470.0  1100.0  2560.0\n",
      "1096  2  55   9   UW  205.0  308.0  1025.0  2650.0\n",
      "1097  2  55   9   UW  235.0  329.0  1151.0  2560.0\n",
      "1098  2  55  10   ER  213.0  533.0  1425.0  1830.0\n",
      "1099  2  55  10   ER  214.0  535.0  1412.0  1800.0\n",
      "\n",
      "[440 rows x 8 columns]\n",
      "      0   1   2    3      4      5       6       7\n",
      "1220  3  62   1   IY  228.0  460.0  3300.0  3950.0\n",
      "1221  3  62   1   IY  200.0  400.0  3400.0  3850.0\n",
      "1222  3  62   2  *IH  205.0  600.0  2550.0  4000.0\n",
      "1223  3  62   2  *IH  205.0  610.0  2500.0  4100.0\n",
      "1224  3  62   3  *EH  225.0  600.0  2750.0  3600.0\n",
      "...  ..  ..  ..  ...    ...    ...     ...     ...\n",
      "1455  3  73   8   UH  320.0  520.0  1600.0  3150.0\n",
      "1456  3  73   9   UW  307.0  460.0  1460.0  3070.0\n",
      "1457  3  73   9   UW  300.0  400.0  1700.0  3000.0\n",
      "1458  3  73  10   ER  300.0  540.0  1770.0  2040.0\n",
      "1459  3  73  10   ER  286.0  540.0  2050.0  2300.0\n",
      "\n",
      "[240 rows x 8 columns]\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Now we make find the center of gravity for each phoneme using the four last rows:\n",
    "\n",
    "To do this, we transform the dataframe into numpy arrays, which I found easier to work for calculations."
   ],
   "id": "45002085c8edb882"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:32:16.144741Z",
     "start_time": "2024-09-14T12:32:16.131270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "phonemes_center = np.full((10,4),[.0,.0,.0,.0])\n",
    "for i in range(10):\n",
    "    vectors1 = (type1_training[type1_training.iloc[:,2] == i+1].iloc[:,4:8]).to_numpy()\n",
    "    vectors2 = (type2_training[type2_training.iloc[:,2] == i+1].iloc[:,4:8]).to_numpy()\n",
    "    vectors3 = (type3_training[type3_training.iloc[:,2] == i+1].iloc[:,4:8]).to_numpy()\n",
    "    phonemes_center[i,:] = (sum(vectors1)+sum(vectors2)+sum(vectors3)) /(vectors1.shape[0]+vectors2.shape[0]+vectors3.shape[0])\n",
    "print(phonemes_center)\n",
    "\n",
    "    "
   ],
   "id": "9839971e2a2ac96c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 194.21666667  300.675      2652.54166667 3253.41666667]\n",
      " [ 195.55833333  437.75833333 2320.65833333 2965.625     ]\n",
      " [ 185.          586.45       2177.66666667 2897.55833333]\n",
      " [ 177.425       804.96666667 1970.46666667 2767.29166667]\n",
      " [ 186.7         724.11666667 1349.025      2717.56666667]\n",
      " [ 179.68333333  827.95       1193.83333333 2720.44166667]\n",
      " [ 183.26666667  594.30833333  903.89166667 2707.40833333]\n",
      " [ 195.71666667  469.53333333 1138.68333333 2642.7       ]\n",
      " [ 198.89166667  353.68333333  951.875      2605.98333333]\n",
      " [ 187.75833333  508.1        1562.26666667 1912.28333333]]\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Now we can make a classifier function\n",
    "\n",
    "The function receives a 4x1 array and checks which center of gravity is closest to determine the correct phoneme. We add 1 at the end because python counts from 0.\n"
   ],
   "id": "9230a15d8c6b7119"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:41:22.992079Z",
     "start_time": "2024-09-14T12:41:22.986355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classifier(argument):\n",
    "    distances = np.full(10,.0)\n",
    "    for i in range(10):\n",
    "        distances[i] = np.linalg.norm(argument-phonemes_center[i])\n",
    "    return distances.argmin()+1\n",
    "    "
   ],
   "id": "117d31e161bf31d0",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Accuracy",
   "id": "4fc3caa8fa510ef8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We check the accuracy of the classifier with the rest of the data.\n",
   "id": "b8d259258bb8ae22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:59:10.072790Z",
     "start_time": "2024-09-14T12:59:10.053842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "type1_test = type1_vowel.iloc[type1_training_length*20:type1_length*20,:]\n",
    "type2_test = type2_vowel.iloc[type2_training_length*20:type2_length*20+1,:]\n",
    "type3_test = type3_vowel.iloc[type3_training_length*20:type3_length*20+1,:]\n",
    "#print(type1_test)\n",
    "type1_test_np = type1_test.iloc[:,4:8].to_numpy()\n",
    "type2_test_np = type2_test.iloc[:,4:8].to_numpy()\n",
    "type3_test_np = type3_test.iloc[:,4:8].to_numpy()\n",
    "\n",
    "check1 = np.full(type1_test_np.shape[0],False)\n",
    "check2 = np.full(type2_test_np.shape[0],False)\n",
    "check3 = np.full(type3_test_np.shape[0],False)\n",
    "for i in range(type1_test_np.shape[0]):\n",
    "    check1[i] = classifier(type1_test_np[i])== type1_test.iloc[i,2]\n",
    "for i in range(type2_test_np.shape[0]):\n",
    "    check2[i] = classifier(type2_test_np[i])== type2_test.iloc[i,2]\n",
    "for i in range(type3_test_np.shape[0]):\n",
    "    check3[i] = classifier(type3_test_np[i])== type3_test.iloc[i,2]\n",
    "accuracy1 = sum(check1)/type1_test.shape[0]\n",
    "accuracy2 = sum(check2)/type2_test.shape[0]\n",
    "accuracy3 = sum(check3)/type3_test.shape[0]"
   ],
   "id": "2d591dffb143da03",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Results",
   "id": "493220110669e5bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:59:30.602549Z",
     "start_time": "2024-09-14T12:59:30.599314Z"
    }
   },
   "cell_type": "code",
   "source": "print(accuracy1,accuracy2,accuracy3)",
   "id": "5ea343b6b5a891c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4142857142857143 0.75 0.48333333333333334\n"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Discussion\n",
    "\n",
    "The accuracy of this type of classifier is pretty low at least for type 1 and type 3 people, that is, men and children. This may be the result of using a single classifier for all kind of voices. It is possible that the classifier may perform better if it identifies beforehand the type of person before making the decision. In other words, it may be better to have a different classifier for men, women and children: \n"
   ],
   "id": "7e06e40847a0dc48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Men classifier:",
   "id": "da0b5877bbfbaaff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T13:06:34.700059Z",
     "start_time": "2024-09-14T13:06:34.690995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "phonemes_center1 = np.full((10,4),[.0,.0,.0,.0])\n",
    "for i in range(10):\n",
    "    vectors1 = (type1_training[type1_training.iloc[:,2] == i+1].iloc[:,4:8]).to_numpy()\n",
    "    phonemes_center1[i,:] = sum(vectors1)/vectors1.shape[0]\n",
    "\n",
    "def classifier1(argument):\n",
    "    distances = np.full(10,.0)\n",
    "    for i in range(10):\n",
    "        distances[i] = np.linalg.norm(argument-phonemes_center1[i])\n",
    "    return distances.argmin()+1\n"
   ],
   "id": "91bd23d38b538b27",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Women classifier:",
   "id": "841a0284bcc2c48f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T13:06:36.416899Z",
     "start_time": "2024-09-14T13:06:36.409972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "phonemes_center2 = np.full((10,4),[.0,.0,.0,.0])\n",
    "for i in range(10):\n",
    "    vectors2 = (type2_training[type2_training.iloc[:,2] == i+1].iloc[:,4:8]).to_numpy()\n",
    "    phonemes_center2[i,:] = sum(vectors2)/vectors2.shape[0]\n",
    "\n",
    "def classifier2(argument):\n",
    "    distances = np.full(10,.0)\n",
    "    for i in range(10):\n",
    "        distances[i] = np.linalg.norm(argument-phonemes_center2[i])\n",
    "    return distances.argmin()+1\n"
   ],
   "id": "90125b66cefe3ec",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Children classifier:",
   "id": "e1f760dae1e29ba5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T13:07:38.259700Z",
     "start_time": "2024-09-14T13:07:38.252657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "phonemes_center3 = np.full((10,4),[.0,.0,.0,.0])\n",
    "for i in range(10):\n",
    "    vectors3 = (type3_training[type3_training.iloc[:,2] == i+1].iloc[:,4:8]).to_numpy()\n",
    "    phonemes_center3[i,:] = sum(vectors3)/vectors3.shape[0]\n",
    "\n",
    "def classifier3(argument):\n",
    "    distances = np.full(10,.0)\n",
    "    for i in range(10):\n",
    "        distances[i] = np.linalg.norm(argument-phonemes_center3[i])\n",
    "    return distances.argmin()+1"
   ],
   "id": "3ecc69b2a9033994",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The new accuracy becomes: ",
   "id": "22ad312f0b90e27e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T13:08:04.907974Z",
     "start_time": "2024-09-14T13:08:04.891207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(type1_test_np.shape[0]):\n",
    "    check1[i] = classifier1(type1_test_np[i])== type1_test.iloc[i,2]\n",
    "for i in range(type2_test_np.shape[0]):\n",
    "    check2[i] = classifier2(type2_test_np[i])== type2_test.iloc[i,2]\n",
    "for i in range(type3_test_np.shape[0]):\n",
    "    check3[i] = classifier3(type3_test_np[i])== type3_test.iloc[i,2]\n",
    "accuracy1 = sum(check1)/type1_test.shape[0]\n",
    "accuracy2 = sum(check2)/type2_test.shape[0]\n",
    "accuracy3 = sum(check3)/type3_test.shape[0]\n",
    "\n",
    "print(accuracy1,accuracy2,accuracy3)"
   ],
   "id": "de24d804efd91b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571 0.7333333333333333 0.75\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With this, the baseline classifier is somewhat acceptable. However, it needs previous knowledge of the type of person being tested. Otherwise, we would need another classifier that could distinguish between male, female and children before performing the second classifier.",
   "id": "1c92bdba3def02c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
