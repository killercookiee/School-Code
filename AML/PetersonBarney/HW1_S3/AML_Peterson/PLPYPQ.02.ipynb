{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# Load and preprocess the dataset from a text file\n",
        "def load_data(filepath, include_starred=True, use_F0=False):\n",
        "    data = []\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split('\\t')\n",
        "            gender, speaker, phoneme_id, phoneme = parts[:4]\n",
        "            F0, F1, F2, F3 = map(float, parts[4:])\n",
        "\n",
        "            # Check if the phoneme is starred (ambiguous)\n",
        "            is_starred = phoneme.startswith('*')\n",
        "            phoneme = phoneme.replace('*', '')  # Remove asterisk\n",
        "\n",
        "            # Optionally exclude starred data\n",
        "            if not include_starred and is_starred:\n",
        "                continue\n",
        "\n",
        "            # Use F0 if specified, otherwise use only F1, F2, F3\n",
        "            if use_F0:\n",
        "                data.append([float(F0), float(F1), float(F2), float(F3), phoneme])\n",
        "            else:\n",
        "                data.append([float(F1), float(F2), float(F3), phoneme])\n",
        "\n",
        "    # Convert the list into a NumPy array\n",
        "    data = np.array(data)\n",
        "    \n",
        "    # Separate features (X) and labels (y)\n",
        "    X = data[:, :-1].astype(float)  # Features (F1, F2, F3 or F0, F1, F2, F3 depending on use_F0)\n",
        "    y = data[:, -1]                 # Labels (Phonemes)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "def split_data(X, y, random_state=36):\n",
        "    # Train, validation, and test split (80%/10%/10%)\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y) # 80%/20%\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state, stratify=y_temp)  # 80%/10%/10%\n",
        "    \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Train a simple baseline classifier (nearest centroid)\n",
        "def train_baseline_model(X_train, y_train):\n",
        "    phoneme_classes = np.unique(y_train)\n",
        "    centroids = {}\n",
        "\n",
        "    # Calculate the center of gravity (centroid) for each phoneme\n",
        "    for phoneme in phoneme_classes:\n",
        "        centroids[phoneme] = X_train[y_train == phoneme].mean(axis=0)\n",
        "\n",
        "    return centroids\n",
        "\n",
        "# Predict using the baseline classifier\n",
        "def predict_baseline(centroids, X_test):\n",
        "    phonemes = list(centroids.keys())\n",
        "    centroids_array = np.array([centroids[phoneme] for phoneme in phonemes])\n",
        "\n",
        "    # Calculate distances from the centroids\n",
        "    distances = cdist(X_test, centroids_array)\n",
        "    closest_centroids = np.argmin(distances, axis=1)\n",
        "    \n",
        "    return np.array(phonemes)[closest_centroids]\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(X_train, y_train, X_val, y_val):\n",
        "    centroids = train_baseline_model(X_train, y_train)\n",
        "    y_pred = predict_baseline(centroids, X_val)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Try multiple random states to get the best result\n",
        "def find_best_random_state(X, y, num_trials=10):\n",
        "    best_accuracy = 0\n",
        "    best_random_state = None\n",
        "\n",
        "    # Try multiple random states\n",
        "    for seed in range(1, num_trials + 1):\n",
        "        # Split data with the current random state\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, random_state=seed)\n",
        "        \n",
        "        # Evaluate the model on the validation set\n",
        "        accuracy = evaluate_model(X_train, y_train, X_val, y_val)\n",
        "        print(f\"Random State {seed}: Validation Accuracy = {accuracy * 100:.2f}%\")\n",
        "\n",
        "        # Keep track of the best accuracy and random state\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_random_state = seed\n",
        "\n",
        "    print(f\"\\nBest Random State: {best_random_state} with Validation Accuracy = {best_accuracy * 100:.2f}%\")\n",
        "    return best_random_state, best_accuracy\n",
        "\n",
        "# Main\n",
        "def main(filepath, include_starred=True, use_F0=False, num_trials=10, output_file=\"best_random_state.txt\"):\n",
        "    # Load data\n",
        "    X, y = load_data(filepath, include_starred, use_F0)\n",
        "\n",
        "    # Find the best random state\n",
        "    best_random_state, best_accuracy = find_best_random_state(X, y, num_trials)\n",
        "\n",
        "    # Use the best random state to split data\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, random_state=best_random_state)\n",
        "\n",
        "    # Train baseline model (center of gravity)\n",
        "    centroids = train_baseline_model(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = predict_baseline(centroids, X_test)\n",
        "\n",
        "    # Evaluate accuracy on the test set\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nFinal Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Classification report (precision, recall, F1-score)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Output the best random state and results to a text file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(f\"Best Random State: {best_random_state}\\n\")\n",
        "        f.write(f\"Validation Accuracy: {best_accuracy * 100:.2f}%\\n\")\n",
        "        f.write(f\"Final Test Accuracy: {accuracy * 100:.2f}%\\n\")\n",
        "        f.write(\"\\nClassification Report:\\n\")\n",
        "        f.write(report)\n",
        "\n",
        "# Run the main function with the switch for starred data, F0, and multiple random states\n",
        "filepath = 'verified_pb.data'  # Path to the file\n",
        "main(filepath, include_starred=False, use_F0=False, num_trials=100, output_file=\"best_random_state_for_accuracy.txt\")  # Adjust as needed\n",
        "\n",
        "# In my tests if I used starred data the validation accuracy was almost the same without it, but the test accuracy is mutch better.\n",
        "# Using or not using F0 doesn't really matter.\n",
        "# The seed number is for making sure that on every run you get the same output values. Also with \"num_trials\" you can run x number of random seeds and only the best one (best validation accuracy) is exported (in my tests it was number 36 with starred data and 29 without them).\n",
        "\n",
        "# For help I mainly used https://scikit-learn.org/stable/ (documentation and examples)\n",
        "\n",
        "# Barta MÃ¡rk Endre - PLPYPQ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
